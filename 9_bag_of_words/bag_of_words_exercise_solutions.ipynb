{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KYoVrnewenmh"
   },
   "source": [
    "### Bag of words: Solutions\n",
    "\n",
    "\n",
    "- In this Exercise, you are going to classify whether a given movie review is **positive or negative**.\n",
    "- you are going to use Bag of words for pre-processing the text and apply different classification algorithms.\n",
    "- Sklearn CountVectorizer has the inbuilt implementations for Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JW6MPIjib_4G"
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from  sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kDATDCL8NMML"
   },
   "source": [
    "### **About Data: IMDB Dataset**\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - review\n",
    "        - sentiment\n",
    "- Reviews are the statements given by users after watching the movie.\n",
    "- sentiment feature tells whether the given review is positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "beL29JwEb_7O",
    "outputId": "cf0a9e1e-b80b-4447-d759-0828baba2620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I first saw Jake Gyllenhaal in Jarhead (2005) ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I enjoyed the movie and the story immensely! I...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had a hard time sitting through this. Every ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's hard to imagine that anyone could find th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is one military drama I like a lot! Tom B...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  I first saw Jake Gyllenhaal in Jarhead (2005) ...  positive\n",
       "1  I enjoyed the movie and the story immensely! I...  positive\n",
       "2  I had a hard time sitting through this. Every ...  negative\n",
       "3  It's hard to imagine that anyone could find th...  negative\n",
       "4  This is one military drama I like a lot! Tom B...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. read the data provided in the same directory with name 'movies_sentiment_data.csv' and store it in df variable\n",
    "df = pd.read_csv(\"movies_sentiment_data.csv\")\n",
    "\n",
    "\n",
    "#2. print the shape of the data\n",
    "print(df.shape)\n",
    "\n",
    "#3. print top 5 datapoints\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a new column \"Category\" which represent 1 if the sentiment is positive or 0 if it is negative\n",
    "df['Category'] = df['sentiment'].apply(lambda x: 1 if x =='positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSwPM7mub_9S",
    "outputId": "2b68719c-b7f4-48b8-a41e-3f95cca9f2f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9500\n",
       "0    9500\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the distribution of 'Category' and see whether the Target labels are balanced or not.\n",
    "\n",
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IB97QiFCcAAe"
   },
   "outputs": [],
   "source": [
    "#Do the 'train-test' splitting with test size of 20%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.review, df.Category, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtr4mSLEMWiU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-pUGPqwMrDQ"
   },
   "source": [
    "**Exercise-1**\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative.\n",
    "\n",
    "**Note:**\n",
    "- use CountVectorizer for pre-processing the text.\n",
    "\n",
    "- use **Random Forest** as the classifier with estimators as 50 and criterion as entropy.\n",
    "- print the classification report.\n",
    "\n",
    "**References**:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CbldZv03MWkB",
    "outputId": "cf70d361-da12-46a9-8d59-73cdba9bad91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83      1849\n",
      "           1       0.85      0.83      0.84      1951\n",
      "\n",
      "    accuracy                           0.84      3800\n",
      "   macro avg       0.84      0.84      0.84      3800\n",
      "weighted avg       0.84      0.84      0.84      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),                                                    #initializing the vectorizer\n",
    "    ('random_forest', (RandomForestClassifier(n_estimators=50, criterion='entropy')))      #using the RandomForest classifier\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As you can see above, for both the classes (positive and negative sentiment) we got more than 80% precision, recall and f1- score. This seems to be an acceptable performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMVvGzqXSFYr"
   },
   "source": [
    "**Exercise-2**\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative..\n",
    "\n",
    "**Note:**\n",
    "- use CountVectorizer for pre-processing the text.\n",
    "- use **KNN** as the classifier with n_neighbors of 10 and metric as 'euclidean'.\n",
    "- print the classification report.\n",
    "\n",
    "**References**:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tYkY77S6MWng",
    "outputId": "53275bdc-4629-464c-d26f-00075b080174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.64      1849\n",
      "           1       0.66      0.64      0.65      1951\n",
      "\n",
      "    accuracy                           0.65      3800\n",
      "   macro avg       0.65      0.65      0.65      3800\n",
      "weighted avg       0.65      0.65      0.65      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "                \n",
    "     ('vectorizer', CountVectorizer()),   \n",
    "      ('KNN', (KNeighborsClassifier(n_neighbors=10, metric = 'euclidean')))   #using the KNN classifier with 10 neighbors \n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hmmm..here the performance of various metrics (precision, recall etc.) seem to be lower (~60 %). Let's try one more classifier and then discuss why performance is varying so much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise-3**\n",
    "\n",
    "1. using sklearn pipeline module create a classification pipeline to classify the movie review's positive or negative..\n",
    "\n",
    "**Note:**\n",
    "- use CountVectorizer for pre-processing the text.\n",
    "- use **Multinomial Naive Bayes** as the classifier.\n",
    "- print the classification report.\n",
    "\n",
    "**References**:\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85      1849\n",
      "           1       0.88      0.82      0.85      1951\n",
      "\n",
      "    accuracy                           0.85      3800\n",
      "   macro avg       0.85      0.85      0.85      3800\n",
      "weighted avg       0.85      0.85      0.85      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1. create a pipeline object\n",
    "clf = Pipeline([\n",
    "                \n",
    "     ('vectorizer', CountVectorizer()),   \n",
    "      ('Multi NB', MultinomialNB())   #using the Multinomial Naive Bayes classifier \n",
    "])\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "#4. print the classfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That's great! MultinomialNB model for both the classes (positive and negative sentiment) we got more than 80% precision, recall and f1- score and performed equally good with Random Forest. This seems to be an acceptable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you write some observations of why model like KNN fails to produce good results unlike RandomForest and MultinomialNB?\n",
    "\n",
    "- As Machine learning algorithms does not work on Text data directly, we need to convert them into numeric vector and feed that into models while training.\n",
    "- In this process, we convert text into a very **high dimensional numeric vector** using the technique of Bag of words.\n",
    "- Model like K-Nearest Neighbours(KNN) doesn't work well with high dimensional data because with large number of dimensions, it becomes difficult for the algorithm to calculate distance in each dimension. In higher dimensional space, the cost to calculate distance becomes expensive and hence impacts the performance of model.\n",
    "- The easy calculation of probabilities for the words in corpus(Bag of words) and storing them in contigency table is the major reason for the Multinomial NaiveBayes to be a text classification friendly algorithm.\n",
    "- As Random Forest uses Bootstrapping(Row and column Sampling) with many decision tree and overcomes the high variance and overfitting of high dimensional data and also uses feature importance of words for better classifing the categories.\n",
    "- Machine Learning is like trial and error scientific method, where we keep trying all the possible algorithms we have and select the one which give good results and satisfy the requirements like latency, interpretability etc.\n",
    "\n",
    "Refer these resources to get good idea:\n",
    "- https://stackabuse.com/k-nearest-neighbors-algorithm-in-python-and-scikit-learn/\n",
    "- https://analyticsindiamag.com/naive-bayes-why-is-it-favoured-for-text-related-tasks/"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BOW_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
