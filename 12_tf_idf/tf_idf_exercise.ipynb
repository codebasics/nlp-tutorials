{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVrcHNZpQLUz"
   },
   "source": [
    "### **TF-IDF: Exercises**\n",
    " \n",
    "- Humans ðŸ‘¦ show different emotions/feelings based on the situations and communicate them through facial expressions or in form of words.\n",
    " \n",
    "- In Social Media like Twitter and Instagram, many people express their views through comments about a particular event/scenario and these comments may address the feelings like sadness, happiness, joy, sarcasm, fear, and many other.\n",
    " \n",
    "- For a given comment/text, we are going to use classical NLP techniques and classify under which emotion that particular comment belongs!\n",
    " \n",
    "- We are going to use techniques like Bag of grams, n-grams, TF-IDF, etc. for text representation and apply different classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wU5KDovsV9ez"
   },
   "source": [
    "### **About Data: Emotion Detection**\n",
    "\n",
    "Credits: https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - Comment\n",
    "        - Emotion\n",
    "- Comment are the statements or messages regarding to a particular event/situation.\n",
    "\n",
    "- Emotion feature tells whether the given comment is fear ðŸ˜¨, Anger ðŸ˜¡, Joy ðŸ˜‚.\n",
    "\n",
    "- As there are only 3 classes, this problem comes under the **Multi-Class Classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "8ML2s0KWVXmv",
    "outputId": "4284d452-b3f4-4998-a2bf-9fd7aa273207"
   },
   "outputs": [],
   "source": [
    "#import pandas library\n",
    "\n",
    "\n",
    "#read the dataset with name \"Emotion_classify_Data.csv\" and store it in a variable df\n",
    "\n",
    "\n",
    "#print the shape of dataframe\n",
    "\n",
    "\n",
    "#print top 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "joLuZmFpT-fY",
    "outputId": "77d48614-f6b3-4227-e90e-dc8ddb17381b"
   },
   "outputs": [],
   "source": [
    "#check the distribution of Emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qPxiqT_TT-hx",
    "outputId": "d58985b6-c81c-48b5-de9b-74735bb6b133"
   },
   "outputs": [],
   "source": [
    "#Add the new column \"Emotion_num\" which gives a unique number to each of these Emotions\n",
    "#joy --> 0, fear --> 1, anger --> 2\n",
    "\n",
    "\n",
    "#checking the results by printing top 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PE-c0zbDXTEm"
   },
   "source": [
    "### **Modelling without Pre-processing Text data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjJqi7UBT-nr"
   },
   "outputs": [],
   "source": [
    "#import train-test split\n",
    "\n",
    "\n",
    "#Do the 'train-test' splitting with test size of 20%\n",
    "#Note: Give Random state 2022 and also do the stratify sampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5lAD0iqGcdCn",
    "outputId": "4efb3c3c-0ad4-4501-d815-35a902095848"
   },
   "outputs": [],
   "source": [
    "#print the shapes of X_train and X_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t57hw7gOVXuW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6h8ZZLxZd79"
   },
   "source": [
    "\n",
    "**Attempt 1** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with only trigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGg2iXv6g40l",
    "outputId": "3f895ca5-7606-4220-b9a2-7c26d9160a9b"
   },
   "outputs": [],
   "source": [
    "#import CountVectorizer, RandomForest, pipeline, classification_report from sklearn \n",
    "\n",
    "\n",
    "#1. create a pipeline object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I08-kc_JYCNL"
   },
   "source": [
    "\n",
    "**Attempt 2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with both unigram and bigrams.\n",
    "- use **Multinomial Naive Bayes** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zetSmBrXmjM",
    "outputId": "b372f53c-8cbc-496f-ef4d-9fecff044230"
   },
   "outputs": [],
   "source": [
    "#import MultinomialNB from sklearn\n",
    "\n",
    "\n",
    "\n",
    "#1. create a pipeline object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Wde4r_-YwU-"
   },
   "source": [
    "\n",
    "**Attempt 3** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with both unigram and Bigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0dG2tc0X7SK",
    "outputId": "f6eddad9-a55b-4fde-eea2-2cbc002f6d4e"
   },
   "outputs": [],
   "source": [
    "#1. create a pipeline object\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmrXmL_3Z2y6"
   },
   "source": [
    "\n",
    "**Attempt 4** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using **TF-IDF vectorizer** for Pre-processing the text.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "djsDsThaaCSO",
    "outputId": "b4514ab2-f6ad-45e1-b91b-e88393e975e5"
   },
   "outputs": [],
   "source": [
    "#import TfidfVectorizer from sklearn\n",
    "\n",
    "\n",
    "\n",
    "#1. create a pipeline object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ACq6pDkZ4sA"
   },
   "source": [
    "<h3>Use text pre-processing to remove stop words, punctuations and apply lemmatization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tj_xYgthX7UF"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load english language model and create nlp object from it\n",
    "nlp = spacy.load(\"en_core_web_sm\") \n",
    "\n",
    "\n",
    "#use this utility function to get the preprocessed text data\n",
    "def preprocess(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    \n",
    "    return \" \".join(filtered_tokens) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqW1i19wX7Xq"
   },
   "outputs": [],
   "source": [
    "# create a new column \"preprocessed_comment\" and use the utility function above to get the clean data\n",
    "# this will take some time, please be patient\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q24oRlMcai9l"
   },
   "source": [
    "**Build a model with pre processed text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahdd2mgxX7dM"
   },
   "outputs": [],
   "source": [
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "#Note: Use the preprocessed_Comment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqonfpeYasOE"
   },
   "source": [
    "**Let's check the scores with our best model till now**\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1wYgFs3auLQ"
   },
   "source": [
    "**Attempt1** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the Data.\n",
    "\n",
    "**Note:**\n",
    "- using CountVectorizer with both unigrams and bigrams.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Khtu32z1XmmE",
    "outputId": "b5f67051-d0e3-4e2e-e342-8297938090ce"
   },
   "outputs": [],
   "source": [
    "#1. create a pipeline object\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9GZPaQbbJbx"
   },
   "source": [
    "\n",
    "**Attempt 2** :\n",
    "\n",
    "1. using the sklearn pipeline module create a classification pipeline to classify the data.\n",
    "\n",
    "**Note:**\n",
    "- using **TF-IDF vectorizer** for pre-processing the text.\n",
    "- use **RandomForest** as the classifier.\n",
    "- print the classification report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2y1Cy4Bauxu",
    "outputId": "ac6bf255-a218-400c-c4a9-790f4a89dfb1"
   },
   "outputs": [],
   "source": [
    "#1. create a pipeline object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with X_train and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for X_test and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Please write down Final Observations**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ta2cWBUkfKel"
   },
   "source": [
    "## [**Solution**](./tf_idf_exercise_solutions.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "tf_idf_exercise.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
