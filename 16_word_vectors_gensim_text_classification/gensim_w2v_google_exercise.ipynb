{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tQ9agNhCuA7"
   },
   "source": [
    "### **gensim_w2v_classification : Exercise**\n",
    "\n",
    "\n",
    "- In this exercise, you are going to classify whether a given text belongs to one of possible classes ['BUSINESS', 'SPORTS', 'CRIME'].\n",
    "\n",
    "- you are going to use **spacy for pre-processing** the text and **gensim to convert text to numbers** and apply different classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ofUtLwvCATG1"
   },
   "outputs": [],
   "source": [
    "#uncomment the below line and run this cell to install the large english model which is trained on wikipedia data\n",
    "\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7X3B1t16CTAG"
   },
   "outputs": [],
   "source": [
    "#import api from gensim downloader module and load the 'word2vec-google-news-300'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hu-InEjEECf"
   },
   "source": [
    "### **About Data: News Category Classifier**\n",
    "\n",
    "Credits: https://www.kaggle.com/code/hengzheng/news-category-classifier-val-acc-0-65\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - Text\n",
    "        - Category\n",
    "- Text are the description about a particular topic.\n",
    "- Category determine which class the text belongs to.\n",
    "- we have classes mainly of 'BUSINESS', 'SPORTS', 'CRIME' and comes under **Multi-class** classification Problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "6vn-QFK8CTDx",
    "outputId": "3c883d1b-70d6-4b69-e22b-dca2e8fe61d1"
   },
   "outputs": [],
   "source": [
    "#import pandas library\n",
    "\n",
    "\n",
    "\n",
    "#read the dataset \"news_dataset.json\" provided and load it into dataframe \"df\"\n",
    "\n",
    "\n",
    "\n",
    "#print the shape of data\n",
    "\n",
    "\n",
    "#print the top5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KeqskgcECTFk",
    "outputId": "00e48bd0-5220-41cf-c67e-b9002046cbd0"
   },
   "outputs": [],
   "source": [
    "#check the distribution of labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NhCfiihaHSoP",
    "outputId": "24c01159-1993-45de-e368-e209c6e35c2c"
   },
   "outputs": [],
   "source": [
    "#Add the new column which gives a unique number to each of these labels \n",
    "\n",
    "\n",
    "\n",
    "#check the results with top 5 rows\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3BR4NrchH8ax"
   },
   "source": [
    "### Now we will convert the text into a vector using gensim's word2vec embeddings.\n",
    "### We will do this in three steps,\n",
    "\n",
    "- 1. Preprocess the text to remove stop words, punctuations and get lemma for each word.\n",
    "\n",
    "- 2. Get word vectors for each of the words in a pre-processed sentence.\n",
    "\n",
    "- 3. Take a mean of all word vectors to derive the numeric representation of the entire news article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "uMO6FaLDHSrE"
   },
   "outputs": [],
   "source": [
    "#use this utility function to get the pre-processed text.\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\") # if this fails then run \"python -m spacy download en_core_web_lg\" to download that model\n",
    "\n",
    "def preprocess_and_vectorize(text):\n",
    "    # remove stop words and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "        \n",
    "    return wv.get_mean_vector(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oZ6_L48ACTJQ"
   },
   "outputs": [],
   "source": [
    "#create a new column \"vector\" that store the vector representation of text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "HKiYDkx7MUD6",
    "outputId": "44dd0f12-9b93-4c61-a41b-dd5195a09ffb"
   },
   "outputs": [],
   "source": [
    "# print the top 5 rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RN33REq1MERj"
   },
   "source": [
    "**Train-Test splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Zv1KVVq6CTK2"
   },
   "outputs": [],
   "source": [
    "#import the train_test_split\n",
    "\n",
    "\n",
    "\n",
    "#Do the 'train-test' splitting with test size of 20% with random state of 2022 and stratify sampling too\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9dsTSIbhMOYt"
   },
   "source": [
    "**Reshaping the X_train and X_test so as to fit for models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q3i8wLGwCTOW",
    "outputId": "00b2df28-7363-4523-ca33-3c3c0ddacbc5"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "#reshapes the X_train and X_test using 'stack' function of numpy. Store the result in new variables \"X_train_2d\" and \"X_test_2d\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wiG1QWtMpp0"
   },
   "source": [
    "**Attempt 1:**\n",
    "\n",
    "\n",
    "- use gensim embeddings for text vectorization.\n",
    "\n",
    "- use Decision Tree as the classifier.\n",
    "\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lAakbqF-MJJr",
    "outputId": "180add4f-f4f7-4a33-f319-3aac074d76ca"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "#1. creating a Decision Tree model object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhM_5JfRM71N"
   },
   "source": [
    "**Attempt 2:**\n",
    "\n",
    "\n",
    "- use gensim embeddings for text vectorization.\n",
    "- use MultinomialNB as the classifier after applying the MinMaxscaler.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMJLxZmqMj75",
    "outputId": "6cdf468d-69a1-485f-df11-f19cae9372ea"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "#doing scaling because Negative values will not pass into Naive Bayes models\n",
    "\n",
    "\n",
    "\n",
    "#1. creating a MultinomialNB model object \n",
    "\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings(scaled) and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M01PKr8_NMnd"
   },
   "source": [
    "**Attempt 3:**\n",
    "\n",
    "\n",
    "- use gensim embeddings for text vectorization.\n",
    "- use KNeighborsClassifier as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AaPLpci6Mj9j",
    "outputId": "6bb46ebc-eb83-469b-be0b-940519fdd7cb"
   },
   "outputs": [],
   "source": [
    "from  sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "#1. creating a KNN model object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbvfcU3bNWYD"
   },
   "source": [
    "**Attempt 4:**\n",
    "\n",
    "\n",
    "- use gensim embeddings for text vectorization.\n",
    "- use RandomForestClassifier as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-Gu3HREMkBf",
    "outputId": "9bce9078-5e89-4be9-eb75-a905397b17c6"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#1. creating a Random Forest model object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGARs-VGN3B6"
   },
   "source": [
    "**Attempt 5:**\n",
    "\n",
    "\n",
    "- use gensim embeddings for text vectorization.\n",
    "- use GradientBoostingClassifier as the classifier.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wG5_sqe1MkES",
    "outputId": "bb518b4a-1ba2-4304-d953-1e2276063ef6"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#1. creating a GradientBoosting model object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rdL1ogVuOCmx"
   },
   "source": [
    "**Print the confusion Matrix with the best model got**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "F6FGhChsMJL_",
    "outputId": "691388a5-4fe6-444c-9e8a-9fd804ffa825"
   },
   "outputs": [],
   "source": [
    "#finally print the confusion matrix for the best model: GradientBoostingClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**Solution**](./gensim_w2v_google_solution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
