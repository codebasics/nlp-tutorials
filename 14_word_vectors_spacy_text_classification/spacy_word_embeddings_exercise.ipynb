{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4Qiw872tJm5"
   },
   "source": [
    "### **spacy_text_classification : Exercise**\n",
    "\n",
    "\n",
    "- In this exercise, you are going to classify whether a given text belongs to one of possible classes ['BUSINESS', 'SPORTS', 'CRIME'].\n",
    "\n",
    "- you are going to use spacy for pre-processing the text, convert text to numbers and apply different classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bitKkWZnWGe",
    "outputId": "4779b05e-0078-4389-a57f-8cab8b9aa8ee"
   },
   "outputs": [],
   "source": [
    "#uncomment the below line and run this cell to install the large english model which is trained on wikipedia data\n",
    "\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "nfwmJvdDnWIq"
   },
   "outputs": [],
   "source": [
    "#import spacy and load the language model downloaded\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOfdVUDOwC4y"
   },
   "source": [
    "### **About Data: News Category Classifier**\n",
    "\n",
    "Credits: https://www.kaggle.com/code/hengzheng/news-category-classifier-val-acc-0-65\n",
    "\n",
    "\n",
    "- This data consists of two columns.\n",
    "        - Text\n",
    "        - Category\n",
    "- Text are the description about a particular topic.\n",
    "- Category determine which class the text belongs to.\n",
    "- we have classes mainly of 'BUSINESS', 'SPORTS', 'CRIME' and comes under **Multi-class** classification Problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "qA7qNgVenWL7",
    "outputId": "3f41a23c-af84-4774-9379-3247074a0084"
   },
   "outputs": [],
   "source": [
    "#import pandas library\n",
    "\n",
    "\n",
    "\n",
    "#read the dataset \"news_dataset.json\" provided and load it into dataframe \"df\"\n",
    "\n",
    "\n",
    "\n",
    "#print the shape of data\n",
    "\n",
    "\n",
    "#print the top5 rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8uMg291enWN0",
    "outputId": "fabf1b28-09f7-4aed-b43d-dc7d3365e321"
   },
   "outputs": [],
   "source": [
    "#check the distribution of labels \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "rPu41FMfnWRc",
    "outputId": "0928da61-f016-4091-bc2a-0c9e447eccf5"
   },
   "outputs": [],
   "source": [
    "#Add the new column \"label_num\" which gives a unique number to each of these labels \n",
    "\n",
    "\n",
    "\n",
    "#check the results with top 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MChU23cwy2u"
   },
   "source": [
    "### **Preprocess the text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "gg2NzymmqRMG"
   },
   "outputs": [],
   "source": [
    "#use this utility function to preprocess the text\n",
    "#1. Remove the stop words\n",
    "#2. Convert to base form using lemmatisation\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    filtered_tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TvMxzat8qtPb"
   },
   "outputs": [],
   "source": [
    "#create a new column \"preprocessed_text\" which store the clean form of given text [use apply and lambda function]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "UN7vG1Gqq2Kv",
    "outputId": "186e1189-816b-4650-9e38-a12b9bc8e1bc"
   },
   "outputs": [],
   "source": [
    "#print the top 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMT8vW6lxUCH"
   },
   "source": [
    "### **Get the spacy embeddings for each preprocessed text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Totfo3RinWTQ"
   },
   "outputs": [],
   "source": [
    "#create a new column \"vector\" that store the vector representation of each pre-processed text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "o6xPUWyFnWW0",
    "outputId": "b8c347c3-98ce-40ea-c51a-d4f0596b2d0d"
   },
   "outputs": [],
   "source": [
    "#print the top 5 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ok6jIl3yHmT"
   },
   "source": [
    "**Train-Test splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmVG4s2onWYz"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaneRpe_yPN8"
   },
   "source": [
    "**Reshape the X_train and X_test so as to fit for models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsW_POgXzE48",
    "outputId": "4367a34c-c9fc-41e2-b1ae-29577648f32b"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#reshapes the X_train and X_test using 'stack' function of numpy. Store the result in new variables \"X_train_2d\" and \"X_test_2d\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RKhDtigyfDm"
   },
   "source": [
    "**Attempt 1:**\n",
    "\n",
    "\n",
    "- use spacy glove embeddings for text vectorization.\n",
    "\n",
    "- use Decision Tree as the classifier.\n",
    "\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPxr0V68zE-y",
    "outputId": "15d1877c-5cf7-4ca0-de9b-522f3c6178ea"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "#1. creating a Decision Tree model object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQdHIem6zANo"
   },
   "source": [
    "**Attempt 2:**\n",
    "\n",
    "\n",
    "- use spacy glove embeddings for text vectorization.\n",
    "- use MultinomialNB as the classifier after applying the MinMaxscaler.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJiRqXsRzE7F",
    "outputId": "b904000a-c812-4e2e-eb17-7594bc087838"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "#doing scaling because Negative values will not pass into Naive Bayes models\n",
    "\n",
    "\n",
    "\n",
    "#1. creating a MultinomialNB model object \n",
    "\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings(scaled) and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJbv-mxR0n4r"
   },
   "source": [
    "**Attempt 3:**\n",
    "\n",
    "\n",
    "- use spacy glove embeddings for text vectorization.\n",
    "- use KNeighborsClassifier as the classifier after applying the MinMaxscaler.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UU0BNgVuzFAv",
    "outputId": "d242d458-2474-4f3d-9f61-0c74b184bb2f"
   },
   "outputs": [],
   "source": [
    "from  sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "#1. creating a KNN model object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKE0byVj04LO"
   },
   "source": [
    "**Attempt 4:**\n",
    "\n",
    "\n",
    "- use spacy glove embeddings for text vectorization.\n",
    "- use RandomForestClassifier as the classifier after applying the MinMaxscaler.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K9c8jZEUzOjr",
    "outputId": "49e97ed9-59e1-4e90-e53c-08bffbc54abb"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#1. creating a Random Forest model object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W5DsqLBp1BGR"
   },
   "source": [
    "**Attempt 5:**\n",
    "\n",
    "\n",
    "- use spacy glove embeddings for text vectorization.\n",
    "- use GradientBoostingClassifier as the classifier after applying the MinMaxscaler.\n",
    "- print the classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YF-3k8RzzOmf",
    "outputId": "8eff0156-6b5a-445f-bc0b-69ba2af8c4bc"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "#1. creating a GradientBoosting model object\n",
    "\n",
    "\n",
    "\n",
    "#2. fit with all_train_embeddings and y_train\n",
    "\n",
    "\n",
    "\n",
    "#3. get the predictions for all_test_embeddings and store it in y_pred\n",
    "\n",
    "\n",
    "\n",
    "#4. print the classfication report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hjatMREK15os"
   },
   "source": [
    "**Print the confusion Matrix with the best model got**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "6jlO1jfx145r",
    "outputId": "f45972c2-adb1-4bd5-e699-092400ea527d"
   },
   "outputs": [],
   "source": [
    "#finally print the confusion matrix for the best model: GradientBoostingClassifier\n",
    "\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**Solution**](./spacy_word_embeddings_solution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
